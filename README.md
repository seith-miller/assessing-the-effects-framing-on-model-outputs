# Assessing the Effects of Framing on Model Outputs

This repository contains a Python application designed to evaluate how framings of prompts differently affects the responses generated by large language models like OpenAI's GPT. It includes tools to process YAML files containing various framed and unframed prompts, submit these prompts to the OpenAI API, and collect the responses.

## Features

- **Prompt Processing**: Converts YAML prompt definitions into queries for the OpenAI API.
- **Response Collection**: Gathers and stores responses from the OpenAI API.
- **Configurable**: Uses a config file to manage API keys and other settings securely.

## Prerequisites

Before you begin, ensure you have the following installed:
- Python 3.7 or higher
- pip (Python package installer)

## Installation

Clone the repository to your local machine:

```bash
git clone https://github.com/yourusername/assessing-the-effects-framing-on-model-outputs.git
cd assessing-the-effects-framing-on-model-outputs
Install the required Python packages:

bash
pip install -r requirements.txt
Configuration
Copy the config_template.ini to config.ini and replace INSERT_YOUR_API_KEY_HERE with your actual OpenAI API key:

ini
[openai]
api_key = your-real-api-key
Note: Do not commit config.ini to your version control system.

Usage
To run the application and process the prompts, use:

bash
python prompt_processor.py
This script reads the prompts from prompts.yaml, interacts with the OpenAI API, and stores the responses in output_responses.json.

Testing
Run the unit tests to ensure that everything is set up correctly:

bash
python3 -m unittest test_prompt_processor.py

find . -type f ! -path './.git/*' ! -path './venv/*' ! -path './__pycache__/*' -exec echo {} \; -exec cat {} \;

